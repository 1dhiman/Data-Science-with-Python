{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbours [source]('http://scikit-learn.org/stable/modules/neighbors.html#neighbors')\n",
    "\n",
    "`sklearn.neighbors`  \n",
    "* **Unsupervised** nearest neighbors is the foundation of many other learning methods, notably manifold learning and spectral clustering. \n",
    "* **Supervised** neighbors-based learning comes in two flavors: classification for data with discrete labels, and regression for data with continuous labels.\n",
    "\n",
    "The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The number of samples can be a user-defined constant (**k-nearest** neighbor learning), or vary based on the local density of points (**radius-based** neighbor learning).\n",
    "\n",
    "Neighbors-based methods are known as **non-generalizing** machine learning methods, since they simply “remember” all of its training data (possibly transformed into a fast indexing structure such as a Ball Tree or KD Tree.).\n",
    "\n",
    "Being a **non-parametric method**, it is often successful in classification situations where the decision boundary is very irregular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
